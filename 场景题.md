1. 如何排查线上问题？
    * F12打开开发工具，看一下是不是前端问题，比如如果接口响应返回了，但是页面没显示。总之，就是看对应的接口（自己后端提供的接口）是不是正常的，返回的数据是不是正常
    * 查看已有的线上日志
    * 测试环境复现生产环境场景
    * debug打日志
2. SQL如何优化（查询优化）？
   * 避免使用select *： select *不会走覆盖索引，会有大量的回表
   * 小表驱动大表：以小表数据集为条件查询更快，对于in、exist关键字
   * 批量操作：可以避免多次请求数据库，而是合成后再批量操作
   * 多用limit：对于有些只需查找前面几条，比如排序前几条的，此时最好用limit，不然会查整张表（用了limit，再查找到指定数量的行后就会停止扫描了）
3. 分库分表是什么，为什么要这样？
   分库分表是数据库架构中的一种水平扩展手段，核心思想是把原来集中在一个数据库实例、一张大表中的数据，按某种规则分成多个数据库或多张结构相同的小表。为什么？
   * 单机容量瓶颈：单表行数过多会使B+树层级变深，从而索引和回表代价增高；单实例磁盘/内存容量有上限；单库的QPS有上限，高并发下可能不太满足
   * 单库单表很大时不好维护，使用分库分表可以按不同业务分，降低维护难度
   分库分表带来的问题？
   * 单机事务->分布式事务，本来是一个事务操作，现在可能要操作好几个库或表，可能使性能下降
   * 跨分片无法直接Join，需要应用层聚合
   * 自增主键失效，即原来一个id可能拆分后有多个相同id出现，可以使用数据库分段自增（步长=分片数）缓解
   * 如果要排序，此时要查所有分片，然后归并，再取前几个数据
   * 运维监控难度增大
4. 怎么设计高并发系统？
    * 系统拆分：单体->微服务
    * 缓存加速：可以用redis
    * MQ削峰：kafka
    * 数据分离：考虑分库分表，分库就是解决数据库连接数太多，性能不好的问题
    * 读写分离：主从库，主库用于写，从库用于读，使主库压力减小
    * 服务监控：Prothemus+Grafana
5. 设计高并发、可抗突发流量、高可用的系统
   * 前端：静态资源优化与分发（CDN）：将静态资源缓存到边缘节点，用户访问时从最近节点获取资源，减轻压力；添加浏览器缓存
   * 网关：可以限流，比如漏桶+令牌桶两级限流
   * 后端服务：
    - 微服务架构：将系统拆分为多个微服务，每个服务可以独立开发和部署
    - 应对突发流量可以使用MQ（kafka）削峰
    - 水平扩展多个服务节点，使请求均衡落在不同节点上处理，增加并发性（可以利用Nginx反向代理服务器来将客户端请求分发给不同的后端服务器节点）
    - 每个微服务都部署了多个相同实例，所有这些实例节点都会向服务注册中心注册自己。当某个实例宕机，会被注册中心检测出故障（心跳机制），然后注册中心将故障实例节点从可用列表中剔除，此时请求就是分配给其它健康服务节点，而不会发给宕机的节点了，从而实现高可用
   * 数据库层面：
    - 添加缓存层，比如访问磁盘数据库前先添加一层中间缓冲层-redis，存储热点数据 
    - 读写分离
    - 分库分表
   * 服务监控：Prothemus+Grafana 
6. kafka用于削峰的流程？
   以电商抢购活动为例：
   * 瞬间可能有100万用户点击“立即购买”按钮，如果没有kafka，那么100万个请求会直接打到后端的服务，造成服务崩溃；
   * 引入kafka后，前端服务不会创建订单，而是将下单信息直接写到kafka的topic中（kafka自身的写入是非常快的），一旦消息写入kafka，后端的服务为kafka消费者，它会以自己能够承受的速度从kafka中消费消息，从而不会让后端服务挂掉。从流量上看就是将突发的流量缓冲起来，然后平缓的去消费
7. 某个网站(Web)响应很慢，可能有什么原因，怎么排查问题
   * 网络问题
     - `DNS`解析慢：`dig`看解析耗时
     - 网络延迟或丢包:`ping`,丢包>1%就值得就一步考究
     - 带宽不足(尤其是大文件传输)
     - `TLS`握手耗时过长:可能证书颁发慢
   * 服务器资源瓶颈
     - `CPU`负载高(代码死循环等):`top`指令检测
     - 磁盘IO瓶颈：`iostat`命令
     - 内存不足:`free`查看
     - 网络连接数超限:`ss -ant`、`netstat -ant`命令
   * 数据库性能问题
     - 慢查询日志：可能是全表扫描
     - 缓存失效(如`Redis`未命中,就会穿透到数据库进行较慢的访问)
   * 代码问题
     - 低效算法
     - 阻塞式IO调用   
8. `TCP`和`UDP`进行100MB数据传输时的大致过程
    * `TCP`:
        - 三次握手建立连接
        - 数据传输:
            * 数据分段:按最大报文段长度MSS进行数据分段,再给每个数据段加上源端口、目标端口、序号、确认号等
            * 可靠传输:确认+重传
            * 流量控制+拥塞控制
        - 数据接收:`TCP`在接收数据时是按序接收的,会根据数据段中的序号对数据进行排序,如果接收方接收到了乱序的数据段,那么它也会重组有序后才传给应用层.`TCP`对于丢包会进行重传,以此保证可靠传输的接收
        - 四次挥手断开连接
    * `UDP`:
        - 数据封装和发送:`UDP`不像`TCP`那样需要建立连接,发送端可以直接将100MB数据进行封装.它会将数据分成多个较小的`UDP`数据包(通常是根据网络层的`MTU`来确定每个`UDP`数据报的大小)
        - 数据传输:`UDP`没有确认和重传,所以不能保证数据一定能够成功到达,而且数据报会出现乱序到达的情况
        - 数据接收:服务端的`UDP`应用程序会接收`UDP`数据报.服务端接收到的数据可能不完整,并且可能乱序,因此需要上层应用,即业务层进行处理,如对于乱序处理,可以为每个`UDP`数据报添加一个序号,接收方在应用层按照序号对数据报进行排序即可  
        - `UDP`丢包在应用层的处理办法(下面方法是在应用层实现的)
            * `FEC`前向纠错:发送方添加冗余数据包(如:通过异或运算生成冗余包,可恢复单个丢失包),接收方通过冗余信息恢复丢失的原始数据包
            * 序号+选择性重传(更佳):
                - 序号:发送方的每个`UDP`数据包添加唯一序号
                - 确认:接收方在收到数据包后会向发送方发送确认消息  
                - 计时器:发送方在发送数据包后会启动一个计时器,如果在计时器超时之前没有收到接收方的确认,那么就要重传
                - 重传计数:可以限制重传计数,以免无限重传浪费资源 
9.  生产环境服务器变慢，如何诊断处理？
   * 先全局看，看cpu是否打满（top -h）；内存是否耗尽（free）；磁盘IO操作是否拉满；是否是网络问题
   * 根据各个瓶颈进一步分析：
    - top+火焰图
    - 分析内存占用情况，也可以直接用火焰图
    - 看哪些进程在大量的IO操作
    - ping查看丢包情况，ss -ant查看网络连接数等
   * 最后再从日志看  
10. 服务器出现大量`CLOSE_WAIT`状态是为什么?怎么解决?
   `close_wait`状态是`TCP`四次挥手的时候服务端收到客户端的`FIN`后自己发送`ACK`出现的,服务器出现大量`close_wait`的原因有两种:
   * 服务器内部业务处理占用了极长时间,都没能处理完业务，而主动发送FIN报文；
   * 也有可能是服务器发送数据时阻塞了，即业务线程阻塞了，导致无法主动发送FIN来关闭;
   * 或者服务器自身的业务逻辑有问题,没有执行`close()`方法(即服务端没有发送`FIN`报文)
   * 解决方法:
     - 停止应用程序
     - 修改程序里的bug
11. 分布式多个机器生成id，如何保证不重复？
    用Redis生成id。因为redis的指令操作是单线程的，可以用来生成全局唯一id。可以用redis的原子操作incr和incrby来实现。并且可以使用redis集群来得到高吞吐量，假如一个集群中有5台redis，可以初始化每台redis的值分别为1,2,3,4,5，步长都是5
12. 限流算法：计数器法、滑动窗口法、漏桶算法和令牌桶算法
    * 计数器法：设定一个时间窗口，在这个窗口内最多允许N次请求，超过则拒绝（存在突发流量问题，如时间窗口末尾的上下沿可能会有双倍请求）
    * 滑动窗口法：将时间窗口划分为多个小的时间片（如1秒分成10个100ms的小窗口），记录每个小窗口内的请求次数，并计算当前滑动窗口总请求数是否超限（更精确控制请求速率，因为窗口更小）
    * 漏桶算法：请求直接放入桶中，但是桶会以固定速率处理请求，即平滑流量，削峰，类似kafka，响应延迟可能较高
    * 令牌桶算法：系统以固定速率向桶中添加令牌，请求到来时需要获取令牌（桶中有令牌才能处理这个请求）才能被处理。桶有容量上限，当令牌满时不新增
13. 限流算法中的计数器法和滑动窗口法在请求数超过时间窗口内设定的阈值时会直接拒绝请求；漏桶算法和令牌桶不是简单直接的拒绝，漏桶是当请求注入桶满时会丢弃多余的，令牌桶是令牌注入满时丢弃多余的令牌。滑动窗口移动时是按一个小窗口滑动的，和计数器法中按固定时间窗口移动不同，滑动窗口管理更精细
14. 削峰和限流是不同的：削峰是让后端服务自己慢慢消费，不会拒绝任何一条消息；而限流是流量超过限制就会拒绝请求，被拒绝的请求要么直接报错，要么重试
15. 怎么防止服务崩溃？
    * 异常捕获：为了防止下游任务启动失败让当前任务崩溃，则可以用异常捕获
    * 资源管理：比如用RAll机制（智能指针）等
    * 打日志，便于崩溃时的快速定位
16. 延时队列实现：延时队列是一种特殊的队列，其特点是元素在插入后必须等待一定时间才能被取出。它常用于需要延迟执行任务的场景，如消息重试等
    * 底层数据结构用priority_queue实现，每个元素带有一个TTL的属性，堆顶是最先到期的元素，当到期了就可以执行此任务，否则要继续等
17. 如何保证库存扣减（<=>如何防止超卖）（超卖就是由于多个redis命令不是原子性的，不是整体的，导致可能某个客户端读取后为1，然后判断通过，认为此时还有库存，但是就在这个客户端读了之后；另一个客户端已经执行了减1，导致此时客户端其实是售罄了，此时还减就是超卖了）
    保证库存扣减的关键在于确保在并发场景下，库存操作的原子性和一致性。常见的方法有：乐观锁、悲观锁、redis原子操作（lua脚本）等
18. OOM（内存不足）可能原因
    * 内存泄漏：不再使用的资源未能释放，导致耗尽可用资源
    * 无限或不合理的递归：比如没有终止条件等
    * 一次性申请太大内存，超过了进程地址空间的限制
    * 频繁new、delete导致大量内存碎片，导致没有符合条件的连续空闲内存了
    * 可以使用Valgrind工具查看；也可以分析由于内存不足崩溃时的coredump文件；也可以通过pprof看内存占比火焰图，定位是哪些函数内存占比高
19. qps一直上升，什么时候会崩溃，从哪里崩溃：qps上升会因为资源耗尽而崩溃，具体崩溃位置取决于此时的系统瓶颈，通常可能是数据库、CPU、内存等
    * 数据库通常是最容易出现瓶颈的地方，如mysql默认最大连接数为150，若qps上升导致连接数超限，新请求将被拒绝
    * cpu使用率过高也会导致请求处理延迟，影响整体吞吐
    * 若qps上升导致大量对象被创建，就可能导致堆内存不足
20. 并发读写会导致数据不一致（因为可能读写混合），需要在读也加锁：写操作通常不是原子的，即一个简单的写操作，底层可能有多个步骤，如果不加锁，那么读操作就可能读到中间态，产生不一致
21. 设计一个游戏排行榜，要求能够实时查看自己的排名和全服前几名：此需求要考虑排序、读写频繁、快速查询、并发一致性、扩展性（如果用户量过大就要分布式）
    * 数据结构：用redis的sorted-set，用里面的score作为玩家排名的根据
    * 写入流程：将新分数和用户id写入redis，同时异步发一条消息到kafka，然后刷到mysql里面做持久化保存；如果key丢失就可以从mysql中重建
    * 读取流程：直接用redis的原生读取操作即可，可用根据用户id读取到它的分数，也可以读到topN
    * 扩展：如果用户规模很大，单机redis会成为瓶颈，此时就可用cluster集群
22. 秒杀系统设计：需要考虑高并发突发流量、库存扣减、防止超卖、容灾等机制
    * 将页面做成纯静态页面部署到CDN上，与后端服务完全分离，用户浏览页面不冲击后端服务
    * 接入层：网关层可以限流，如果请求量巨大也可以在网关层削峰
    * 业务层：使用redis。在秒杀开始前，可以先把数据提前加载到redis，查询时更快（预热）。当用户消费后，可以使用lua脚本实现原子扣减，当减到0就是库存告罄，防止超卖
    * 使用mysql作用持久化机制，将操作最后持久化到磁盘
23. Flink是一个开源的、分布式、高性能、高可用的流计算框架，其核心思想就是有状态流计算。在Flink中批处理（有限数据集）是流处理（无限数据集）的一个特例。Flink最强大的是有状态计算（类似动规），比如计算每秒/每分钟的总销售额、一段时间的热门商品排行榜，即要使用之前的状态。Flink和kafka经常结合使用，flink作为kafka的消费者，从指定topic中消费数据，并进行计算，然后返回结果，比如：数据源->kafka->flink（kafka的后端消费者）->结果输出（如数据库、另一个kafka topic等）。注意不是所有情况下用kafka的时候都要用flink，对于有状态计算，即数据处理需要从单条消息处理升级到跨消息（即跨状态）的复杂计算时就可用flink。对于实习中，我都是没有涉及到有状态的计算的，每条消息都是独立的，消费一条消息时不需要知道其它任何消息，因此都是后端服务直接消费kafka，没用flink
24. cpu打满的情况（排查：top+火焰图）
    * 计算密集型任务
      - 业务逻辑本身需要大量计算
      - 代码中有低效算法或死循环
      - 代码中大量的临时对象，造成频繁GC
    * 大量的上下文切换
      - 当线程数远超CPU核心数时，操作系统会花费大量资源来进行调度和切换
      - 锁竞争激烈：多个线程争抢一把锁，如果线程是自旋锁，那么它会一直重试，占cpu
    * 遭受攻击
      - DDos攻击：比如SYN洪泛攻击，服务器会收到大量伪造的ip客户端的请求，由于它们实际不存在，因此服务端会重试，占用cpu资源
      - 挖矿病毒：系统被入侵，被植入了挖矿程序，它会偷偷占用所有cpu资源进行加密货币挖矿  
25. 高并发的常用手段
    * 应用架构层面
      * 分布式与集群化：使用多个节点组成集群，通过负载均衡将请求分发到不同节点处理
      * 对于耗时操作，比如刷写日志到磁盘这些，要异步解耦，不能使主线程阻塞
    * 缓存层面 
      * 使用缓存技术，避免每次都直接去数据库访问
    * 数据库层面
      * 数据库读写分离：主库负载写，多个从库负责读，分担主库压力
      * 分库分表：分库分表使查询效率更高，并发能力更强
      * SQL优化：建立合适的索引等
    * 前端层面
      * 可以使用浏览器缓存等手段 
26. 10w并发写怎么保证线程安全：肯定不能用全局锁，不然不满足这么大的并发写
    * 分布式方案，使用水平扩展多个节点来将压力分散，这是高并发的关键
    * 分片锁（类似leveldb的分片锁），每一个分片一把锁，让数据映射到这些分片中去
    * kafka削峰，使流量平滑进行导入后端服务，这样可以避免大量的并发竞争
    * 如果不是临界区的共享资源，可以用CAS无锁的原子操作
27. 100w/s的请求怎么进行限速？
    redis限速（利用的是计数法），但是每个redis的qps上限是10w/s，因此可以把100w的请求分成100份，每一份随机到不同的redis节点就行
28. 现在给如下资源：10TB硬盘、100G内存，请问怎么存2TB大小的表比较合理？
    为了快速查找肯定是要用哈希表，但是100G内存不能存下所有表记录，因此要把所有记录存到硬盘中。对于SSD硬盘，最小单位是Block块-4KB，那么可以定义一个8字节的block映射，然后共有2500个映射，把这2500*8字节=20000字节存入内存即可，到时候访问时就先通过内存快速查找block位置，再去磁盘中的哈希表中找
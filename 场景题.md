1. 如何排查线上问题？
    * F12打开开发工具，看一下是不是前端问题，比如如果接口响应返回了，但是页面没显示。总之，就是看对应的接口（自己后端提供的接口）是不是正常的，返回的数据是不是正常
    * 查看已有的线上日志
    * 测试环境复现生产环境场景
    * debug打日志
2. SQL如何优化（查询优化）？
   * 避免使用select *： select *不会走覆盖索引，会有大量的回表
   * 小表驱动大表：以小表数据集为条件查询更快，对于in、exist关键字
   * 批量操作：可以避免多次请求数据库，而是合成后再批量操作
   * 多用limit：对于有些只需查找前面几条，比如排序前几条的，此时最好用limit，不然会查整张表（用了limit，再查找到指定数量的行后就会停止扫描了）
3. 分库分表是什么，为什么要这样？
   分库分表是数据库架构中的一种水平扩展手段，核心思想是把原来集中在一个数据库实例、一张大表中的数据，按某种规则分成多个数据库或多张结构相同的小表。为什么？
   * 单机容量瓶颈：单表行数过多会使B+树层级变深，从而索引和回表代价增高；单实例磁盘/内存容量有上限；单库的QPS有上限，高并发下可能不太满足
   * 单库单表很大时不好维护，使用分库分表可以按不同业务分，降低维护难度
   分库分表带来的问题？
   * 单机事务->分布式事务，本来是一个事务操作，现在可能要操作好几个库或表，性能下降
   * 跨分片无法直接Join，需要应用层聚合
   * 自增主键失效，即原来一个id可能拆分后有多个相同id出现，可以使用数据库分段自增（步长=分片数）缓解
   * 如果要排序，此时要查所有分片，然后归并，再取前几个数据
   * 运维难度增大
4. 怎么设计高并发系统？
    * 系统拆分：单体->微服务
    * 缓存加速：可以用redis
    * MQ削峰：kafka
    * 数据分离：考虑分库分表，分库就是解决数据库连接数太多，性能不好的问题
    * 读写分离：主从库，主库用于写，从库用于读，使主库压力减小
    * 服务监控：Prothemus+Grafana
5. kafka用于削峰的流程？
   以电商抢购活动为例：
   * 瞬间可能有100万用户点击“立即购买”按钮，如果没有kafka，那么100万个请求会直接打到后端的服务，造成服务崩溃；
   * 引入kafka后，前端服务不会创建订单，而是将下单信息直接写到kafka的topic中（kafka自身的写入是非常快的），一旦消息写入kafka，后端的服务为kafka消费者，它会以自己能够承受的速度从kafka中消费消息，从而不会让后端服务挂掉。从流量上看就是将突发的流量缓冲起来，然后平缓的去消费
6. 某个网站(Web)响应很慢，可能有什么原因，怎么排查问题
   * 网络问题
     - `DNS`解析慢：`dig`看解析耗时
     - 网络延迟或丢包:`ping`,丢包>1%就值得就一步考究
     - 带宽不足(尤其是大文件传输)
     - `TLS`握手耗时过长:可能证书颁发慢
   * 服务器资源瓶颈
     - `CPU`负载高(代码死循环等):`top`指令检测
     - 磁盘IO瓶颈：`iostat`命令
     - 内存不足:`free`查看
     - 网络连接数超限:`ss`命令
   * 数据库性能问题
     - 慢查询日志：可能是全表扫描
     - 缓存失效(如`Redis`未命中,就会穿透到数据库进行较慢的访问)
   * 代码问题
     - 低效算法
     - 阻塞式IO调用   
7. `TCP`和`UDP`进行100MB数据传输时的大致过程
    * `TCP`:
        - 三次握手建立连接
        - 数据传输:
            * 数据分段:按最大报文段长度MSS进行数据分段,再给每个数据段加上源端口、目标端口、序号、确认号等
            * 可靠传输:确认+重传
            * 流量控制+拥塞控制
        - 数据接收:`TCP`在接收数据时是按序接收的,会根据数据段中的序号对数据进行排序,如果接收方接收到了乱序的数据段,那么它也会重组有序后才传给应用层.`TCP`对于丢包会进行重传,以此保证可靠传输的接收
        - 四次挥手断开连接
    * `UDP`:
        - 数据封装和发送:`UDP`不像`TCP`那样需要建立连接,发送端可以直接将100MB数据进行封装.它会将数据分成多个较小的`UDP`数据包(通常是根据网络层的`MTU`来确定每个`UDP`数据报的大小)
        - 数据传输:`UDP`没有确认和重传,所以不能保证数据一定能够成功到达,而且数据报会出现乱序到达的情况
        - 数据接收:服务端的`UDP`应用程序会接收`UDP`数据报.服务端接收到的数据可能不完整,并且可能乱序,因此需要上层应用,即业务层进行处理,如对于乱序处理,可以为每个`UDP`数据报添加一个序号,接收方在应用层按照序号对数据报进行排序即可  
        - `UDP`丢包在应用层的处理办法(下面方法是在应用层实现的)
            * `FEC`前向纠错:发送方添加冗余数据包(如:通过异或运算生成冗余包,可恢复单个丢失包),接收方通过冗余信息恢复丢失的原始数据包
            * 序号+选择性重传(更佳):
                - 序号:发送方的每个`UDP`数据包添加唯一序号
                - 确认:接收方在收到数据包后会向发送方发送确认消息  
                - 计时器:发送方在发送数据包后会启动一个计时器,如果在计时器超时之前没有收到接收方的确认,那么就要重传
                - 重传计数:可以限制重传计数,以免无限重传浪费资源 
8. 生产环境服务器变慢，如何诊断处理？
   * 先全局看，看cpu是否打满（top -h）；内存是否耗尽（free）；磁盘IO操作是否拉满；是否是网络问题
   * 根据各个瓶颈进一步分析：
    - top+火焰图
    - 分析内存占用情况，也可以直接用火焰图
    - 看哪些进程在大量的IO操作
    - ping查看丢包情况，ss查看网络连接数等
   * 最后再从日志看  
9. 服务器出现大量`CLOSE_WAIT`状态是为什么?怎么解决?
   `close_wait`状态是`TCP`四次挥手的时候服务端收到客户端的`FIN`后自己发送`ACK`出现的,服务器出现大量`close_wait`的原因有两种:
   * 服务器内部业务处理占用了极长时间,都没能处理完业务，而主动发送FIN报文；
   * 也有可能是服务器发送数据时阻塞了，即业务线程阻塞了，导致无法主动发送FIN来关闭;
   * 或者服务器自身的业务逻辑有问题,没有执行`close()`方法(即服务端没有发送`FIN`报文)
   * 解决方法:
     - 停止应用程序
     - 修改程序里的bug
10. 分布式多个机器生成id，如何保证不重复？
    用Redis生成id。因为redis的指令操作是单线程的，可以用来生成全局唯一id。可以用redis的原子操作incr和incrby来实现。并且可以使用redis集群来得到高吞吐量，假如一个集群中有5台redis，可以初始化每台redis的值分别为1,2,3,4,5，步长都是5
11. 限流算法：计数器法、滑动窗口法、漏桶算法和令牌桶算法
    * 计数器法：设定一个时间窗口，在这个窗口内最多允许N次请求，超过则拒绝（存在突发流量问题，如时间窗口末尾的上下沿可能会有双倍请求）
    * 滑动窗口法：将时间窗口划分为多个小的时间片（如1秒分成10个100ms的小窗口），记录每个小窗口内的请求次数，并计算当前滑动窗口总请求数是否超限（更精确控制请求速率，因为窗口更小）
    * 漏桶算法：请求直接放入桶中，但是桶会以固定速率处理请求，即平滑流量，削峰，类似kafka，响应延迟可能较高
    * 令牌桶算法：系统以固定速率向桶中添加令牌，请求到来时需要获取令牌（桶中有令牌才能处理这个请求）才能被处理。桶有容量上限，当令牌满时不新增
12. 削峰和限流是不同的：削峰是让后端服务自己慢慢消费，不会拒绝任何一条消息；而限流是流量超过限制就会拒绝请求，被拒绝的请求要么直接报错，要么重试
13. 怎么防止服务崩溃？
    * 异常捕获：为了防止下游任务启动失败让当前任务崩溃，则可以用异常捕获
    * 资源管理：比如用RAll机制（智能指针）等
    * 打日志，便于崩溃时的快速定位
14. 延时队列实现：延时队列是一种特殊的队列，其特点是元素在插入后必须等待一定时间才能被取出。它常用于需要延迟执行任务的场景，如消息重试等
    * 底层数据结构用priority_queue实现，每个元素带有一个TTL的属性，堆顶是最先到期的元素，当到期了就可以执行此任务，否则要继续等
15. 如何保证库存扣减（<=>如何防止超卖）（超卖就是由于多个redis命令不是原子性的，不是整体的，导致可能某个客户端读取后为1，然后判断通过，认为此时还有库存，但是就在这个客户端读了之后；另一个客户端已经执行了减1，导致此时客户端其实是售罄了，此时还减就是超卖了）
    保证库存扣减的关键在于确保在并发场景下，库存操作的原子性和一致性。常见的方法有：乐观锁、悲观锁、redis原子操作（lua脚本）等
16. OOM（内存不足）可能原因
    * 内存泄漏：不再使用的资源未能释放，导致耗尽可用资源
    * 无限或不合理的递归：比如没有终止条件等
    * 一次性申请太大内存，超过了进程地址空间的限制
    * 频繁new、delete导致大量内存碎片，导致没有符合条件的连续空闲内存了
    * 可以使用Valgrind工具查看；也可以分析由于内存不足崩溃时的coredump文件；也可以通过pprof看内存占比火焰图，定位是哪些函数内存占比高
17. qps一直上升，什么时候会崩溃，从哪里崩溃：qps上升会因为资源耗尽而崩溃，具体崩溃位置取决于此时的系统瓶颈，通常可能是数据库、CPU、内存等
    * 数据库通常是最容易出现瓶颈的地方，如mysql默认最大连接数为150，若qps上升导致连接数超限，新请求将被拒绝
    * cpu使用率过高也会导致请求处理延迟，影响整体吞吐
    * 若qps上升导致大量对象被创建，就可能导致堆内存不足
18. 并发读写会导致数据不一致（因为可能读写混合），需要在读也加锁：写操作通常不是原子的，即一个简单的写操作，底层可能有多个步骤，如果不加锁，那么读操作就可能读到中间态，产生不一致
19. 设计一个游戏排行榜，要求能够实时查看自己的排名和全服前几名：此需求要考虑排序、读写频繁、快速查询、并发一致性、扩展性（如果用户量过大就要分布式）
    * 数据结构：用redis的sorted-set，用里面的score作为玩家排名的根据
    * 写入流程：将新分数和用户id写入redis，同时异步发一条消息到kafka，然后刷到mysql里面做持久化保存；如果key丢失就可以从mysql中重建
    * 读取流程：直接用redis的原生读取操作即可，可用根据用户id读取到它的分数，也可以读到topN
    * 扩展：如果用户规模很大，单机redis会成为瓶颈，此时就可用cluster集群
20. 秒杀系统设计：需要考虑高并发突发流量、库存扣减、防止超卖、容灾等机制
    * 将页面做成纯静态页面部署到CDN上，与后端服务完全分离，用户浏览页面不冲击后端服务
    * 接入层：网关层可以限流，如果请求量巨大也可以在网关层削峰
    * 业务层：使用redis。在秒杀开始前，可以先把数据提前加载到redis，查询时更快（预热）。当用户消费后，可以使用lua脚本实现原子扣减，当减到0就是库存告罄，防止超卖
    * 使用mysql作用持久化机制，将操作最后持久化到磁盘
21. Flink是一个开源的、分布式、高性能、高可用的流计算框架，其核心思想就是有状态流计算。在Flink中批处理（有限数据集）是流处理（无限数据集）的一个特例。Flink最强大的是有状态计算（类似动规），比如计算每秒/每分钟的总销售额、一段时间的热门商品排行榜，即要使用之前的状态。Flink和kafka经常结合使用，flink作为kafka的消费者，从指定topic中消费数据，并进行计算，然后返回结果，比如：数据源->kafka->flink（kafka的后端消费者）->结果输出（如数据库、另一个kafka topic等）。注意不是所有情况下用kafka的时候都要用flink，对于有状态计算，即数据处理需要从单条消息处理升级到跨消息（即跨状态）的复杂计算时就可用flink。对于实习中，我都是没有涉及到有状态的计算的，每条消息都是独立的，消费一条消息时不需要知道其它任何消息，因此都是后端服务直接消费kafka，没用flink
22. cpu打满的情况（排查：top+火焰图）
    * 计算密集型任务
      - 业务逻辑本身需要大量计算
      - 代码中有低效算法或死循环
      - 代码中大量的临时对象，造成频繁GC
    * 大量的上下文切换
      - 当线程数远超CPU核心数时，操作系统会花费大量资源来进行调度和切换
      - 锁竞争激烈：多个线程争抢一把锁，如果线程是自旋锁，那么它会一直重试，占cpu
    * 遭受攻击
      - DDos攻击：比如SYN洪泛攻击，服务器会收到大量伪造的ip客户端的请求，由于它们实际不存在，因此服务端会重试，占用cpu资源
      - 挖矿病毒：系统被入侵，被植入了挖矿程序，它会偷偷占用所有cpu资源进行加密货币挖矿  